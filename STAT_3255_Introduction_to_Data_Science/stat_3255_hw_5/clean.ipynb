{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from uszipcode import SearchEngine\n",
    "import folium\n",
    "\n",
    "df = pd.read_csv(\"nyc_crashes_202301.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used data cleaning process from hw3\n",
    "\n",
    "# replaces the value 0.000000 with missing value\n",
    "df[\"LONGITUDE\"].replace(0.000000, np.nan, inplace=True)\n",
    "df[\"LATITUDE\"].replace(0.000000, np.nan, inplace=True)\n",
    "\n",
    "# create a binary missingness indicator for \"ZIP CODE\" and \"BOROUGH\"\n",
    "# 1 is missing 0 is not missing\n",
    "df['ZIP CODE Missing'] = df['ZIP CODE'].isna().astype(int)\n",
    "df['BOROUGH Missing'] = df['BOROUGH'].isna().astype(int)\n",
    "\n",
    "# create a cross table of the missing patterns of \"ZIP CODE\" and \"BOROUGH\"\n",
    "pd.crosstab(df['ZIP CODE Missing'], df['BOROUGH Missing'])\n",
    "\n",
    "# create a cross table of the missing patterns of \"ZIP CODE\" and \"BOROUGH\"\n",
    "ct = pd.crosstab(df['ZIP CODE Missing'], df['BOROUGH Missing'])\n",
    "\n",
    "# used same function from STAT3255 notes\n",
    "sr = SearchEngine()\n",
    "\n",
    "def nyczip2burough(zip):\n",
    "    nzip = int(zip)\n",
    "    if nzip >= 10001 and nzip <= 10282:\n",
    "        return \"MANHATTAN\"\n",
    "    elif nzip >= 10301 and nzip <= 10314:\n",
    "        return \"STATEN ISLAND\"\n",
    "    elif nzip >= 10451 and nzip <= 10475:\n",
    "        return \"BRONX\"\n",
    "    elif nzip >= 11004 and nzip <= 11109:\n",
    "        return \"QUEENS\"\n",
    "    elif nzip >= 11351 and nzip <= 11697:\n",
    "        return \"QUEENS\"\n",
    "    elif nzip >= 11201 and nzip <= 11256:\n",
    "        return \"BROOKLYN\"\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "# loop through each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # check if either ZIP CODE or BOROUGH is missing\n",
    "    if pd.isnull(row[\"ZIP CODE\"]) or pd.isnull(row[\"BOROUGH\"]):\n",
    "        \n",
    "        # check if both LATITUDE and LONGITUDE are available\n",
    "        if not pd.isnull(row[\"LATITUDE\"]) and not pd.isnull(row[\"LONGITUDE\"]):\n",
    "            \n",
    "            # use reverse geocoding to get the zip code and borough\n",
    "            result = sr.by_coordinates(row[\"LATITUDE\"], row[\"LONGITUDE\"], radius=1, returns=1)\n",
    "            \n",
    "            # check if the result is not empty\n",
    "            if result:\n",
    "                \n",
    "                # get the zip code and borough\n",
    "                zipcode = result[0].zipcode\n",
    "                borough = nyczip2burough(zipcode)\n",
    "                \n",
    "                # update the missing ZIP CODE and BOROUGH in the dataframe\n",
    "                df.at[index, \"ZIP CODE\"] = zipcode\n",
    "                df.at[index, \"BOROUGH\"] = borough\n",
    "\n",
    "# convert lower cases to uppercases\n",
    "df[\"CONTRIBUTING FACTOR VEHICLE 1\"] = df[\"CONTRIBUTING FACTOR VEHICLE 1\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRASH DATE                          0\n",
       "CRASH TIME                          0\n",
       "BOROUGH                           570\n",
       "ZIP CODE                          565\n",
       "LATITUDE                          524\n",
       "LONGITUDE                         524\n",
       "LOCATION                          448\n",
       "ON STREET NAME                   1735\n",
       "CROSS STREET NAME                3489\n",
       "OFF STREET NAME                  4949\n",
       "NUMBER OF PERSONS INJURED           0\n",
       "NUMBER OF PERSONS KILLED            0\n",
       "NUMBER OF PEDESTRIANS INJURED       0\n",
       "NUMBER OF PEDESTRIANS KILLED        0\n",
       "NUMBER OF CYCLIST INJURED           0\n",
       "NUMBER OF CYCLIST KILLED            0\n",
       "NUMBER OF MOTORIST INJURED          0\n",
       "NUMBER OF MOTORIST KILLED           0\n",
       "CONTRIBUTING FACTOR VEHICLE 1      51\n",
       "CONTRIBUTING FACTOR VEHICLE 2    1713\n",
       "CONTRIBUTING FACTOR VEHICLE 3    6062\n",
       "CONTRIBUTING FACTOR VEHICLE 4    6513\n",
       "CONTRIBUTING FACTOR VEHICLE 5    6631\n",
       "COLLISION_ID                        0\n",
       "VEHICLE TYPE CODE 1               125\n",
       "VEHICLE TYPE CODE 2              2463\n",
       "VEHICLE TYPE CODE 3              6110\n",
       "VEHICLE TYPE CODE 4              6525\n",
       "VEHICLE TYPE CODE 5              6633\n",
       "ZIP CODE Missing                    0\n",
       "BOROUGH Missing                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hour variable\n",
    "df[\"CRASH TIME\"] = df[\"CRASH TIME\"].astype(str)\n",
    "df[\"hour\"] = df[\"CRASH TIME\"].str.split(\":\").str[0].astype(int)\n",
    "df[\"minute\"] = df[\"CRASH TIME\"].str.split(\":\").str[1].astype(int)\n",
    "\n",
    "df[\"hour\"] = df.apply(lambda x: x[\"hour\"] + 1 if x[\"minute\"] >= 30 else x[\"hour\"], axis=1)\n",
    "df[\"hour\"] = df[\"hour\"].apply(lambda x: 0 if x == 24 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"injury\"] = df[\"NUMBER OF PERSONS INJURED\"].apply(lambda x: 1 if x >= 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of zip code information\n",
    "\n",
    "from uszipcode import SearchEngine\n",
    "import pandas as pd\n",
    "\n",
    "sr = SearchEngine()\n",
    "\n",
    "borough_zipcodes = {\n",
    "    'Bronx': ['10453', '10457', '10460', '10458', '10467', '10468', '10451', '10452', '10456', '10454', '10455', '10459', '10474'],\n",
    "    'Brooklyn': ['11212', '11213', '11216', '11233', '11238', '11209', '11214', '11228', '11204', '11218', '11219', '11230', '11234', '11236', '11239', '11223', '11224', '11229', '11235', '11201', '11205', '11215', '11217', '11231', '11203', '11210', '11225', '11226', '11207', '11208', '11211', '11222', '11220', '11232', '11206', '11221', '11237'],\n",
    "    'Manhattan': ['10026', '10027', '10030', '10037', '10039', '10001', '10011', '10018', '10019', '10020', '10036', '10029', '10035', '10010', '10016', '10017', '10022', '10012', '10013', '10014', '10004', '10005', '10006', '10007', '10038', '10280', '10002', '10003', '10009', '10021', '10028', '10044', '10065', '10075', '10128', '10023', '10024', '10025'],\n",
    "    'Queens': ['11004', '11101', '11102', '11103', '11104', '11105', '11106', '11351', '11354', '11355', '11356', '11357', '11358', '11359', '11360', '11361', '11362', '11363', '11364', '11365', '11366', '11367', '11412', '11423', '11432', '11433', '11434', '11435', '11436', '11109', '11369', '11370', '11372', '11373', '11377', '11378', '11379', '11385'],\n",
    "    'Staten Island': ['10302', '10303', '10310', '10306', '10307', '10308', '10309', '10312', '10301', '10304', '10305', '10314']\n",
    "}\n",
    "\n",
    "zip_info_list = []\n",
    "\n",
    "for borough, zipcodes in borough_zipcodes.items():\n",
    "    for zipcode in zipcodes:\n",
    "        zip_info = sr.by_zipcode(zipcode).__dict__\n",
    "        zip_info['borough'] = borough\n",
    "        zip_info_list.append(zip_info)\n",
    "\n",
    "df1 = pd.DataFrame(zip_info_list)\n",
    "\n",
    "df1.to_csv('zip_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRASH DATE                          0\n",
       "CRASH TIME                          0\n",
       "BOROUGH                             5\n",
       "ZIP CODE                            0\n",
       "LATITUDE                          106\n",
       "LONGITUDE                         106\n",
       "LOCATION                           58\n",
       "ON STREET NAME                   1710\n",
       "CROSS STREET NAME                3128\n",
       "OFF STREET NAME                  4409\n",
       "NUMBER OF PERSONS INJURED           0\n",
       "NUMBER OF PERSONS KILLED            0\n",
       "NUMBER OF PEDESTRIANS INJURED       0\n",
       "NUMBER OF PEDESTRIANS KILLED        0\n",
       "NUMBER OF CYCLIST INJURED           0\n",
       "NUMBER OF CYCLIST KILLED            0\n",
       "NUMBER OF MOTORIST INJURED          0\n",
       "NUMBER OF MOTORIST KILLED           0\n",
       "CONTRIBUTING FACTOR VEHICLE 1      49\n",
       "CONTRIBUTING FACTOR VEHICLE 2    1584\n",
       "CONTRIBUTING FACTOR VEHICLE 3    5576\n",
       "CONTRIBUTING FACTOR VEHICLE 4    5966\n",
       "CONTRIBUTING FACTOR VEHICLE 5    6071\n",
       "COLLISION_ID                        0\n",
       "VEHICLE TYPE CODE 1               119\n",
       "VEHICLE TYPE CODE 2              2292\n",
       "VEHICLE TYPE CODE 3              5621\n",
       "VEHICLE TYPE CODE 4              5978\n",
       "VEHICLE TYPE CODE 5              6073\n",
       "ZIP CODE Missing                    0\n",
       "BOROUGH Missing                     0\n",
       "hour                                0\n",
       "minute                              0\n",
       "injury                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_code_df = pd.read_csv(\"zip_codes.csv\")\n",
    "df.dropna(subset=['ZIP CODE'], inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert type to integer so that they are the same in both dataframes and merge based on zip code\n",
    "df['ZIP CODE'] = df['ZIP CODE'].astype('int64')\n",
    "merged_df = pd.merge(df, zip_code_df, left_on='ZIP CODE', right_on='zipcode', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4911, 61)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4911, 38)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.drop(['minute', 'CRASH TIME', 'LOCATION', 'ZIP CODE Missing', 'BOROUGH Missing', 'Unnamed: 0', '_sa_instance_state', 'state', 'bounds_east', 'lat', 'bounds_north', 'zipcode_type', 'lng', 'bounds_south', 'zipcode', 'timezone', 'major_city', 'radius_in_miles', 'post_office_city', 'area_code_list', 'common_city_list', 'bounds_west', 'borough'], axis=1, inplace=True)\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns to replace nan values\n",
    "cols_to_replace_nan = ['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3',\n",
    "                       'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5', 'VEHICLE TYPE CODE 1', \n",
    "                       'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5']\n",
    "\n",
    "# replace nan values with \"Unspecified\"\n",
    "for col in cols_to_replace_nan:\n",
    "    merged_df[col] = merged_df[col].fillna(\"Unspecified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns with missing values\n",
    "cols_with_missing = ['land_area_in_sqmi', 'water_area_in_sqmi', 'housing_units', 'occupied_housing_units', 'population',\n",
    "                     'median_home_value', 'population_density', 'median_household_income']\n",
    "# drop rows with missing values in specified columns\n",
    "merged_df = merged_df.dropna(subset=cols_with_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values: BOROUGH                             5\n",
      "ON STREET NAME                   1165\n",
      "CROSS STREET NAME                1136\n",
      "OFF STREET NAME                  1333\n",
      "county                              5\n",
      "CONTRIBUTING FACTOR VEHICLE 1      47\n",
      "CONTRIBUTING FACTOR VEHICLE 2      28\n",
      "CONTRIBUTING FACTOR VEHICLE 3      10\n",
      "CONTRIBUTING FACTOR VEHICLE 4       5\n",
      "CONTRIBUTING FACTOR VEHICLE 5       3\n",
      "VEHICLE TYPE CODE 1                55\n",
      "VEHICLE TYPE CODE 2                68\n",
      "VEHICLE TYPE CODE 3                16\n",
      "VEHICLE TYPE CODE 4                11\n",
      "VEHICLE TYPE CODE 5                 5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_unique = merged_df[['BOROUGH', 'ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME', 'county', 'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3',\n",
    "                       'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5', 'VEHICLE TYPE CODE 1', \n",
    "                       'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5']].nunique()\n",
    "print(\"Number of unique values:\", num_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4899, 38)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"cleaned_nyc_crashes_202301.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Giovanni Lunetta">
<meta name="dcterms.date" content="2023-02-22">

<title>Homework 5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="hw5_files/libs/clipboard/clipboard.min.js"></script>
<script src="hw5_files/libs/quarto-html/quarto.js"></script>
<script src="hw5_files/libs/quarto-html/popper.min.js"></script>
<script src="hw5_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="hw5_files/libs/quarto-html/anchor.min.js"></script>
<link href="hw5_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="hw5_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="hw5_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="hw5_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="hw5_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Homework 5</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Giovanni Lunetta </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 22, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="exercise-8" class="level1">
<h1>Exercise 8</h1>
<p>Using the cleaned NYC crash data, perform classification of injury with support vector machine and compare the results with the benchmark from regularized logistic regression. Use the last week’s data as testing data.</p>
<p>First we preprocess and prepare for modeling</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load the cleaned NYC crash data</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"cleaned_nyc_crashes_202301.csv"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># create list of column names to create dummies for</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>cols_to_dummy <span class="op">=</span> [<span class="st">'BOROUGH'</span>, <span class="st">'ON STREET NAME'</span>, <span class="st">'CROSS STREET NAME'</span>, <span class="st">'OFF STREET NAME'</span>, <span class="st">'county'</span>, <span class="st">'CONTRIBUTING FACTOR VEHICLE 1'</span>, <span class="st">'CONTRIBUTING FACTOR VEHICLE 2'</span>, <span class="st">'CONTRIBUTING FACTOR VEHICLE 3'</span>,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                       <span class="st">'CONTRIBUTING FACTOR VEHICLE 4'</span>, <span class="st">'CONTRIBUTING FACTOR VEHICLE 5'</span>, <span class="st">'VEHICLE TYPE CODE 1'</span>, </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                       <span class="st">'VEHICLE TYPE CODE 2'</span>, <span class="st">'VEHICLE TYPE CODE 3'</span>, <span class="st">'VEHICLE TYPE CODE 4'</span>, <span class="st">'VEHICLE TYPE CODE 5'</span>]</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># create dummies for specified columns</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.get_dummies(df, columns<span class="op">=</span>cols_to_dummy, prefix<span class="op">=</span>cols_to_dummy)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># drop uneeded column</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>df.drop([<span class="st">'Unnamed: 0'</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># drop all null values</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># subset the data to only include the last week</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>df_last_week <span class="op">=</span> df.loc[(df[<span class="st">'CRASH DATE'</span>] <span class="op">&gt;=</span> <span class="st">'01/25/2023'</span>) <span class="op">&amp;</span> (df[<span class="st">'CRASH DATE'</span>] <span class="op">&lt;=</span> <span class="st">'01/31/2023'</span>)]</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_last_week[<span class="st">"CRASH DATE"</span>].value_counts(dropna<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># get the indices of the rows to exclude</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>test_indices <span class="op">=</span> df_last_week.index</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># create df_train by excluding the test data</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> df.drop(test_indices)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_train[<span class="st">"CRASH DATE"</span>].value_counts(dropna<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># convert date_of_crash to datetime</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>df_last_week[<span class="st">'CRASH DATE'</span>] <span class="op">=</span> pd.to_datetime(df_last_week[<span class="st">'CRASH DATE'</span>], <span class="bu">format</span><span class="op">=</span><span class="st">'%m/</span><span class="sc">%d</span><span class="st">/%Y'</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the timestamp as a numerical value</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>df_last_week[<span class="st">'CRASH DATE'</span>] <span class="op">=</span> df_last_week[<span class="st">'CRASH DATE'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co"># convert date_of_crash to datetime</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>df_train[<span class="st">'CRASH DATE'</span>] <span class="op">=</span> pd.to_datetime(df_train[<span class="st">'CRASH DATE'</span>], <span class="bu">format</span><span class="op">=</span><span class="st">'%m/</span><span class="sc">%d</span><span class="st">/%Y'</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the timestamp as a numerical value</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>df_train[<span class="st">'CRASH DATE'</span>] <span class="op">=</span> df_train[<span class="st">'CRASH DATE'</span>].astype(<span class="bu">int</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>01/25/2023    181
01/26/2023    170
01/28/2023    167
01/27/2023    146
01/31/2023    137
01/30/2023    132
01/29/2023    111
Name: CRASH DATE, dtype: int64
01/19/2023    209
01/13/2023    205
01/12/2023    196
01/10/2023    187
01/18/2023    178
01/17/2023    177
01/14/2023    172
01/09/2023    171
01/23/2023    169
01/24/2023    169
01/22/2023    166
01/20/2023    164
01/16/2023    162
01/03/2023    159
01/21/2023    154
01/04/2023    153
01/06/2023    153
01/02/2023    144
01/11/2023    142
01/08/2023    137
01/07/2023    137
01/05/2023    136
01/15/2023    132
Name: CRASH DATE, dtype: int64</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/4b/z0w6x5_n59g_x_9s3qnbx_p80000gn/T/ipykernel_12287/3348097203.py:32: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_last_week['CRASH DATE'] = pd.to_datetime(df_last_week['CRASH DATE'], format='%m/%d/%Y')
/var/folders/4b/z0w6x5_n59g_x_9s3qnbx_p80000gn/T/ipykernel_12287/3348097203.py:34: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_last_week['CRASH DATE'] = df_last_week['CRASH DATE'].astype(int)</code></pre>
</div>
</div>
<p>Now we model</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix, classification_report, roc_auc_score</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># remove the 'injury' column from both dataframes</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> df_train.drop(<span class="st">'injury'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> df_last_week.drop(<span class="st">'injury'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># create the target variables</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> df_train[<span class="st">'injury'</span>]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> df_last_week[<span class="st">'injury'</span>]</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit and evaluate a regularized logistic regression model</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>logreg <span class="op">=</span> LogisticRegression(penalty<span class="op">=</span><span class="st">'l2'</span>, solver<span class="op">=</span><span class="st">'saga'</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>logreg.fit(X_train, y_train)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>y_pred_logreg <span class="op">=</span> logreg.predict(X_test)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>accuracy_logreg <span class="op">=</span> accuracy_score(y_test, y_pred_logreg)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>cm_logreg <span class="op">=</span> confusion_matrix(y_test, y_pred_logreg)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>report_logreg <span class="op">=</span> classification_report(y_test, y_pred_logreg)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>auc_logreg <span class="op">=</span> roc_auc_score(y_test, y_pred_logreg)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit and evaluate a support vector machine model</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>svm <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'linear'</span>)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>svm.fit(X_train, y_train)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>y_pred_svm <span class="op">=</span> svm.predict(X_test)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>accuracy_svm <span class="op">=</span> accuracy_score(y_test, y_pred_svm)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>cm_svm <span class="op">=</span> confusion_matrix(y_test, y_pred_svm)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>report_svm <span class="op">=</span> classification_report(y_test, y_pred_svm)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>auc_svm <span class="op">=</span> roc_auc_score(y_test, y_pred_svm)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the performance metrics</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Logistic Regression Accuracy:"</span>, accuracy_logreg)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Logistic Regression Confusion Matrix:</span><span class="ch">\n</span><span class="st">"</span>, cm_logreg)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Logistic Regression Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, report_logreg)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Logistic Regression AUC:"</span>, auc_logreg)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Support Vector Machine Accuracy:"</span>, accuracy_svm)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Support Vector Machine Confusion Matrix:</span><span class="ch">\n</span><span class="st">"</span>, cm_svm)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Support Vector Machine Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, report_svm)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Support Vector Machine AUC:"</span>, auc_svm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Logistic Regression Accuracy: 0.6216475095785441
Logistic Regression Confusion Matrix:
 [[649   0]
 [395   0]]
Logistic Regression Classification Report:
               precision    recall  f1-score   support

           0       0.62      1.00      0.77       649
           1       0.00      0.00      0.00       395

    accuracy                           0.62      1044
   macro avg       0.31      0.50      0.38      1044
weighted avg       0.39      0.62      0.48      1044

Logistic Regression AUC: 0.5
Support Vector Machine Accuracy: 0.6216475095785441
Support Vector Machine Confusion Matrix:
 [[649   0]
 [395   0]]
Support Vector Machine Classification Report:
               precision    recall  f1-score   support

           0       0.62      1.00      0.77       649
           1       0.00      0.00      0.00       395

    accuracy                           0.62      1044
   macro avg       0.31      0.50      0.38      1044
weighted avg       0.39      0.62      0.48      1044

Support Vector Machine AUC: 0.5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))</code></pre>
</div>
</div>
</section>
<section id="explain-the-parameters-you-used-in-your-fitting-for-each-method." class="level1">
<h1>Explain the parameters you used in your fitting for each method.</h1>
<p>For logistic regression, we used the following parameters: penalty: ‘l2’: This is the regularization technique used for the logistic regression. L2 regularization adds a penalty term to the loss function that is proportional to the square of the magnitude of the coefficients. This helps to prevent overfitting by shrinking the coefficients towards zero.</p>
<p>solver: ‘saga’: This is the algorithm used to optimize the loss function. Saga is a variant of stochastic gradient descent that is efficient for large datasets.</p>
<p>For the support vector machine (SVM), we used the following parameters: kernel: ‘linear’: This is the kernel function used for the SVM. The linear kernel function creates a linear decision boundary between the classes.</p>
</section>
<section id="explain-the-confusion-matrix-return-from-each-fit." class="level1">
<h1>Explain the confusion matrix return from each fit.</h1>
<p>The confusion matrix shows the number of true positives, true negatives, false positives, and false negatives. In this case, both logistic regression and SVM models predicted all samples to be negative (0), resulting in a confusion matrix with 649 true negatives and 395 false negatives. Since there are no true positives or false positives, precision, recall, F1-score, and AUC are not defined.</p>
</section>
<section id="compare-the-performance-of-the-two-approaches-in-terms-of-accuracy-precision-recall-f1-score-and-auc." class="level1">
<h1>Compare the performance of the two approaches in terms of accuracy, precision, recall, F1-score, and AUC.</h1>
<p>In this case, both logistic regression and SVM models predicted all samples to be negative (0), resulting in an accuracy of 62.2%, which is not a good performance. Since there are no true positives or false positives, precision, recall, F1-score, and AUC are not defined. Therefore, we cannot compare the performance of the two approaches using these metrics.</p>
<p>But, in order to explain what these metrics are…</p>
<p>Accuracy is the proportion of correctly classified samples out of all the samples. It is not always a good performance metric, especially if the classes are imbalanced.</p>
<p>Precision is the proportion of true positives out of all the samples predicted to be positive. It measures how accurate the positive predictions are.</p>
<p>Recall is the proportion of true positives out of all the actual positive samples. It measures how well the model is able to identify positive samples.</p>
<p>F1-score is the harmonic mean of precision and recall, and it provides a balanced measure between the two.</p>
<p>AUC (Area Under the ROC Curve) is a measure of the model’s ability to distinguish between positive and negative samples. It is the area under the ROC curve, where ROC stands for Receiver Operating Characteristic. The ROC curve is a plot of the true positive rate (TPR) against the false positive rate (FPR) at different classification thresholds. A perfect classifier has an AUC of 1, while a random classifier has an AUC of 0.5.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
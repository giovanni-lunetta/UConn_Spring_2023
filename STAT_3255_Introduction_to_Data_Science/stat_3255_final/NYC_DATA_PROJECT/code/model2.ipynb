{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/giovanni-lunetta/stat_3255/stat_3255_final/data/cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20complaints = df['Complaint Type'].value_counts().nlargest(20).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top20complaint'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'Complaint Type'] in top20complaints:\n",
    "        df.loc[i, 'top20complaint'] = df.loc[i, 'Complaint Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Complaint Type', axis=1)[['housing_units', 'occupied_housing_units', 'median_home_value', 'population', 'median_household_income', 'population_density', 'top20complaint']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_units</th>\n",
       "      <th>occupied_housing_units</th>\n",
       "      <th>median_home_value</th>\n",
       "      <th>population</th>\n",
       "      <th>median_household_income</th>\n",
       "      <th>population_density</th>\n",
       "      <th>top20complaint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11195.0</td>\n",
       "      <td>10645.0</td>\n",
       "      <td>574200.0</td>\n",
       "      <td>28606.0</td>\n",
       "      <td>75335.0</td>\n",
       "      <td>16269.0</td>\n",
       "      <td>illegal parking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24078.0</td>\n",
       "      <td>22554.0</td>\n",
       "      <td>427100.0</td>\n",
       "      <td>66631.0</td>\n",
       "      <td>57776.0</td>\n",
       "      <td>26903.0</td>\n",
       "      <td>general construction/plumbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37251.0</td>\n",
       "      <td>34843.0</td>\n",
       "      <td>495800.0</td>\n",
       "      <td>98592.0</td>\n",
       "      <td>50799.0</td>\n",
       "      <td>27290.0</td>\n",
       "      <td>street condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12975.0</td>\n",
       "      <td>12227.0</td>\n",
       "      <td>406200.0</td>\n",
       "      <td>38912.0</td>\n",
       "      <td>78667.0</td>\n",
       "      <td>12553.0</td>\n",
       "      <td>missed collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34028.0</td>\n",
       "      <td>30859.0</td>\n",
       "      <td>598000.0</td>\n",
       "      <td>86408.0</td>\n",
       "      <td>42170.0</td>\n",
       "      <td>46966.0</td>\n",
       "      <td>illegal parking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_units  occupied_housing_units  median_home_value  population  \\\n",
       "0        11195.0                 10645.0           574200.0     28606.0   \n",
       "1        24078.0                 22554.0           427100.0     66631.0   \n",
       "2        37251.0                 34843.0           495800.0     98592.0   \n",
       "3        12975.0                 12227.0           406200.0     38912.0   \n",
       "4        34028.0                 30859.0           598000.0     86408.0   \n",
       "\n",
       "   median_household_income  population_density                 top20complaint  \n",
       "0                  75335.0             16269.0                illegal parking  \n",
       "1                  57776.0             26903.0  general construction/plumbing  \n",
       "2                  50799.0             27290.0               street condition  \n",
       "3                  78667.0             12553.0              missed collection  \n",
       "4                  42170.0             46966.0                illegal parking  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# select the variables to scale\n",
    "variables_to_scale = ['housing_units', 'occupied_housing_units', 'median_home_value', 'population', 'median_household_income', 'population_density']\n",
    "\n",
    "# apply the scaler to the selected variables\n",
    "df.loc[:, variables_to_scale] = scaler.fit_transform(df.loc[:, variables_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noise                            36881\n",
       "illegal parking                  34172\n",
       "other                            32376\n",
       "heat/hot water                   29661\n",
       "blocked driveway                 12629\n",
       "unsanitary condition              6686\n",
       "abandoned vehicle                 4981\n",
       "plumbing                          4641\n",
       "missed collection                 4040\n",
       "paint/plaster                     3760\n",
       "derelict vehicles                 3571\n",
       "water system                      3495\n",
       "dirty condition                   3125\n",
       "door/window                       2805\n",
       "rodent                            2778\n",
       "general construction/plumbing     2582\n",
       "street condition                  2444\n",
       "water leak                        2417\n",
       "illegal dumping                   2034\n",
       "electric                          1850\n",
       "sewer                             1810\n",
       "Name: top20complaint, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['top20complaint'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map complaint types to numerical values\n",
    "complaint_map = {'other': 0}\n",
    "for i, complaint in enumerate(top20complaints, 1):\n",
    "    complaint_map[complaint] = i\n",
    "\n",
    "# Replace the complaint types with numerical values\n",
    "df['complaint_code'] = df['top20complaint'].replace(complaint_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['top20complaint'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df.drop('complaint_code', axis=1), df['complaint_code'], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Split the training data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the cleaned data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.drop(['over3h'], axis=1), df['over3h'], test_size=0.2, random_state=42)\n",
    "X_test = df_test.drop(['over3h'], axis=1)\n",
    "y_test = df_test['over3h']\n",
    "\n",
    "# Align the test data with the training data to add any missing columns\n",
    "X_test_aligned, X_train_aligned = X_test.align(X_train, join='outer', axis=1, fill_value=0)\n",
    "X_test = X_test_aligned.loc[:, X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3975/3975 [==============================] - 6s 1ms/step - loss: 2.3953 - accuracy: 0.2322 - val_loss: 2.3765 - val_accuracy: 0.2339\n",
      "Epoch 2/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3765 - accuracy: 0.2383 - val_loss: 2.3753 - val_accuracy: 0.2283\n",
      "Epoch 3/25\n",
      "3975/3975 [==============================] - 4s 1ms/step - loss: 2.3724 - accuracy: 0.2453 - val_loss: 2.3618 - val_accuracy: 0.2427\n",
      "Epoch 4/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3696 - accuracy: 0.2445 - val_loss: 2.3658 - val_accuracy: 0.2356\n",
      "Epoch 5/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3695 - accuracy: 0.2440 - val_loss: 2.3623 - val_accuracy: 0.2401\n",
      "Epoch 6/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3689 - accuracy: 0.2438 - val_loss: 2.3584 - val_accuracy: 0.2532\n",
      "Epoch 7/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3686 - accuracy: 0.2448 - val_loss: 2.3646 - val_accuracy: 0.2340\n",
      "Epoch 8/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3684 - accuracy: 0.2439 - val_loss: 2.3570 - val_accuracy: 0.2465\n",
      "Epoch 9/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3679 - accuracy: 0.2438 - val_loss: 2.3550 - val_accuracy: 0.2457\n",
      "Epoch 10/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3682 - accuracy: 0.2439 - val_loss: 2.3551 - val_accuracy: 0.2483\n",
      "Epoch 11/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3680 - accuracy: 0.2431 - val_loss: 2.3605 - val_accuracy: 0.2436\n",
      "Epoch 12/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3677 - accuracy: 0.2443 - val_loss: 2.3552 - val_accuracy: 0.2490\n",
      "Epoch 13/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3682 - accuracy: 0.2438 - val_loss: 2.3557 - val_accuracy: 0.2522\n",
      "Epoch 14/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3673 - accuracy: 0.2441 - val_loss: 2.3574 - val_accuracy: 0.2519\n",
      "Epoch 15/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3665 - accuracy: 0.2430 - val_loss: 2.3694 - val_accuracy: 0.2332\n",
      "Epoch 16/25\n",
      "3975/3975 [==============================] - 6s 1ms/step - loss: 2.3675 - accuracy: 0.2441 - val_loss: 2.3588 - val_accuracy: 0.2451\n",
      "Epoch 17/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3675 - accuracy: 0.2433 - val_loss: 2.3586 - val_accuracy: 0.2542\n",
      "Epoch 18/25\n",
      "3975/3975 [==============================] - 6s 1ms/step - loss: 2.3678 - accuracy: 0.2437 - val_loss: 2.3637 - val_accuracy: 0.2477\n",
      "Epoch 19/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3677 - accuracy: 0.2445 - val_loss: 2.3737 - val_accuracy: 0.2374\n",
      "Epoch 20/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3679 - accuracy: 0.2446 - val_loss: 2.3739 - val_accuracy: 0.2422\n",
      "Epoch 21/25\n",
      "3975/3975 [==============================] - 6s 1ms/step - loss: 2.3679 - accuracy: 0.2437 - val_loss: 2.3633 - val_accuracy: 0.2472\n",
      "Epoch 22/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3676 - accuracy: 0.2433 - val_loss: 2.3599 - val_accuracy: 0.2427\n",
      "Epoch 23/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3669 - accuracy: 0.2439 - val_loss: 2.3571 - val_accuracy: 0.2463\n",
      "Epoch 24/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3678 - accuracy: 0.2424 - val_loss: 2.3567 - val_accuracy: 0.2579\n",
      "Epoch 25/25\n",
      "3975/3975 [==============================] - 5s 1ms/step - loss: 2.3668 - accuracy: 0.2437 - val_loss: 2.3643 - val_accuracy: 0.2436\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Define model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=10, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(units=5, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(units=21, activation='softmax')\n",
    "])\n",
    "\n",
    "# Define optimizer with learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile model with optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
